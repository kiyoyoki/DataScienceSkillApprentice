{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f762e12d",
   "metadata": {},
   "source": [
    "# 単回帰分析において，最小二乗法，回帰係数，標準誤差，決定係数を理解し，モデルを構築する(2022/02/01)\n",
    "---\n",
    "## 概要\n",
    "---\n",
    "単回帰分析(regression analysis)について調べ，実際にモデルを構築する．その際，最小二乗法・回帰係数・標準誤差・決定係数についても理解する．\n",
    "\n",
    "## 単回帰分析\n",
    "---\n",
    "「気温が観測できたとき，その日のアイスの売り上げが知りたい」「賃貸マンションの床面積が分かるとき，その家賃を知りたい」といったように，ある値から関連のある別の値を予測したいという期待は数多く存在する．そういった場合に利用できる分析アプローチの一つが単回帰分析である．\n",
    "\n",
    "単回帰分析では，$D=\\{(x_1,y_1),...,(x_n,y_n)\\}$といった2変量のデータセットが標本としてある場合に，その関係性を尤もらしく説明できる直線にフィッティングする．すなわち,\n",
    "\n",
    "\\begin{eqnarray}\n",
    "y = \\beta + \\alpha x\n",
    "\\end{eqnarray}\n",
    "\n",
    "という直線(回帰モデル)を考え，データ点の分布に最も近くなるような係数$\\alpha, \\beta$を求めることが単回帰分析の要旨である．この係数をとりわけ回帰係数と呼ぶ．\n",
    "\n",
    "またこのとき，変数$x$を説明変数，$y$を目的変数と呼ぶ．その名の通り，回帰モデルを構築した後，説明変数の値を用いて目的変数の値を予測していくことになる．\n",
    "\n",
    "なお，単回帰分析においては説明変数が一つだけであるが，もちろん説明変数が複数存在する回帰モデルも存在する．この場合，単回帰分析ではなく重回帰分析と呼び名が変わる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe27c28",
   "metadata": {},
   "source": [
    "## 最小二乗法\n",
    "---\n",
    "単回帰モデルを構築するためには，係数$\\alpha, \\beta$を推定することが必要であると述べた．得られたデータ$D$をより良く近似するためには，元となるデータと予測との誤差が最小になればよい．つまり，以下のような誤差の二乗和が最小になるように$\\alpha，\\beta$を決める．これを最小二乗法という．\n",
    "\n",
    "\\begin{eqnarray}\n",
    "L = \\sum_{i=1}^{n}[y_i-(\\beta + \\alpha x_i)]^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "ここで$L$は損失(Loss)を表す関数とみなせる．さらに，データ$D$に平均を0とするような中心化を施していた場合，直線の切片項$\\beta=0$となるから，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "L = \\sum_{i=1}^{n}(y_i-\\alpha x_i)^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "この損失関数の値が最小となるよう最適化すればよいことになる．\n",
    "\n",
    "$L$を最小化する係数$\\alpha, \\beta$を導出する方法はいくつかあるが，先に結果を以下に示す：\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\alpha &=& \\frac{s_{xy}}{s_x} = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum(x_i-\\bar{x})^2} \\\\\n",
    "\\\\\n",
    "\\beta &=& \\bar{y} - \\alpha\\bar{x} = \\bar{y} - \\frac{s_{xy}}{s_x}\\bar{x}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453f00e",
   "metadata": {},
   "source": [
    "### $\\alpha$の導出\n",
    "説明を簡単にするため，先にデータセットを以下のように中心化する：\n",
    "\n",
    "\\begin{eqnarray}\n",
    "X_i &=& x_i - \\bar{x} \\\\\n",
    "Y_i &=& y_i - \\bar{y}\n",
    "\\end{eqnarray}\n",
    "\n",
    "よって損失関数$L$は以下のようになる：\n",
    "\n",
    "\\begin{eqnarray}\n",
    "L = \\sum_{i=1}^{n}(Y_i - \\alpha X_i)^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "この関数を$\\alpha$に関する二次関数とみなしたとき，最小値をとるのは(微分値)=0となるところであるから，(※凸関数であるかの吟味については省略する)\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial L}{\\partial \\alpha} &=& \\frac{\\partial}{\\partial \\alpha}\\sum_{i=1}^{n}(Y_i - \\alpha X_i)^2 \\\\\n",
    "&=& \\sum_{i=1}^{n}-2X_i(Y_i - \\alpha X_i) \\\\\n",
    "&=& -2\\sum_{i=1}^{n}X_iY_i + 2\\alpha\\sum_{i=1}^{n}X_i^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "よって，\n",
    "\\begin{eqnarray}\n",
    "-2\\sum_{i=1}^{n}X_iY_i + 2\\alpha\\sum_{i=1}^{n}X_i^2 = 0\n",
    "\\end{eqnarray}\n",
    "\n",
    "ゆえ，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\alpha &=& \\frac{\\sum_{i=1}^{n}X_iY_i}{\\sum_{i=1}^{n}X_i^2} \\\\\\\\\n",
    "&=& \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum(x_i-\\bar{x})^2} \\\\\\\\\n",
    "&=& \\frac{s_{xy}}{s_x}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa4633",
   "metadata": {},
   "source": [
    "### $\\beta$の導出\n",
    "先の証明で以下のような直線の式が導出できた：\n",
    "\n",
    "\\begin{eqnarray}\n",
    "Y &=& \\alpha X \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "変数変換を元に戻すと，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "y-\\bar{y} &=& \\alpha(x-\\bar{x}) \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "より，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "y &=& \\alpha x -\\alpha\\bar{x} + \\bar{y}\\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "となる．つまり，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "y &=& \\alpha x -\\alpha\\bar{x} + \\bar{y}\\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "となるから，係数を比較して，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\beta &=& -\\alpha\\bar{x} + \\bar{y}\\\\\\\\\n",
    "&=& \\bar{y}-\\alpha\\bar{x} \\\\\\\\\n",
    "&=& \\bar{y}-\\frac{s_{xy}}{s_x}\\bar{x}\n",
    "\\end{eqnarray}\n",
    "\n",
    "となる．よってパラメータ$\\beta$も導出できた．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd2bec",
   "metadata": {},
   "source": [
    "## 単回帰モデルの評価\n",
    "---\n",
    "本説では，単回帰モデルの評価手法について，決定係数，標準誤差，p値について説明する．\n",
    "\n",
    "### 決定係数\n",
    "決定係数は，単回帰分析において用いる二変量の相関係数の二乗で表される値である．つまり，データ$D=\\{(x_1,y_1),...,(x_n,y_n)\\}$があるとして，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "R^2 &=& \\left(\\frac{s_xy}{s_xs_y}\\right)^2 \\\\\n",
    "&=& \\left(\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\right)^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "と表される．相関係数が-1から1までの値をとるので，その二乗である決定係数は0から1までの値をとる．決定係数を寄与率と呼ぶこともある．\n",
    "\n",
    "また，上記の定義は厳密に言うと「最小二乗法を用いて単回帰モデルを最適化した場合」という条件が付いている．これは，最小二乗法が決定係数を最大化するように最適化することによる．\n",
    "\n",
    "決定係数は現状様々な定義が存在しているが，その中でも一般的に知られているものを以下に記す：\n",
    "\n",
    "\\begin{eqnarray}\n",
    "R^2 &=& 1 - \\frac{(残差変動)}{(全変動)} \\\\\n",
    "&=& 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y}_i)^2} \n",
    "\\end{eqnarray}\n",
    "\n",
    "あるいは，\n",
    "\n",
    "\\begin{eqnarray}\n",
    "R^2 &=& \\frac{(回帰変動)}{(全変動)} \\\\\n",
    "&=& \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y}_i)^2}\n",
    "\\end{eqnarray}\n",
    "\n",
    "これら2つの定義はいずれも意味しているものは同じで，「平均値からの偏差(全変動)のうち，回帰モデルによるもの(残差変動)『以外の割合』はどのくらいか」という意味である．抽象的に言い換えると，「説明変数から回帰モデルによって，どれだけ目的変数をよく説明できているか」という意味である．\n",
    "\n",
    "とりうる値は1以下の実数であり，この値が大きいほど回帰モデルはデータ点によくフィットしていることになる．最小二乗法では，回帰モデルとデータ点との値の差(残差変動)を最小化するようにパラメータを最適化していることになる．\n",
    "\n",
    "また補足として，決定係数がゼロになるときは(残差変動)=(全変動)となる時であるが，この時のモデルは最も単純なフィッティングだと捉えることができる．具体的には，傾きゼロ，切片が目的変数の平均値$\\bar{y}$となるような定数の直線でフィッティングした場合がこれにあたる．\n",
    "\n",
    "### 自由度調整済み決定係数\n",
    "単回帰モデルの場合にはそもそも説明変数が一つなので問題になることはないが，重回帰モデルのように説明変数が複数存在する場合，決定係数は増加する傾向にあることが知られている．つまり重回帰分析においては決定係数があまり意味をなさない．\n",
    "\n",
    "これに対処するため，自由度(≒説明変数の数)を考慮した決定係数の定義も存在し，以下のように\n",
    "\n",
    "\\begin{eqnarray}\n",
    "R^2 = 1 - \\frac{\\frac{1}{N-p-1}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\frac{1}{N-1}\\sum_{i=1}^{n}(y_i - \\bar{y}_i)^2} \n",
    "\\end{eqnarray}\n",
    "\n",
    "と表される．$N$は標本の大きさであり，$p$は定数項を除いたパラメータの数である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68dea52",
   "metadata": {},
   "source": [
    "### 標準誤差\n",
    "標準誤差(Standard Error)とは統計量の標準偏差のことで，一般的には標本平均の標準偏差として解釈される．母集団からn個の標本を抽出するとき，標準誤差は以下のように与えられる：\n",
    "\n",
    "\\begin{eqnarray}\n",
    "(SE) = \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "$\\sigma$は母分散であり，これが不明な場合には不偏分散$s$を用いることも多い．標本の数を増やすことで，母平均の区間推定の精度が上げられる．中心極限定理により，十分に大きい標本数を用意すれば，標本平均は母平均に(ほぼ)等しくなる．\n",
    "\n",
    "さて，ここまでが一般的な標準誤差の解釈であるが，回帰分析における標準誤差の活用はどのようなものだろうか．回帰分析においては「回帰モデルの推定値の標準誤差」「回帰係数の推定値の標準誤差」という2つの解釈が存在する．\n",
    "\n",
    "### 回帰モデルの推定値の標準誤差\n",
    "### 回帰係数の推定値の標準偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845732cc",
   "metadata": {},
   "source": [
    "### p値"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601a0c3",
   "metadata": {},
   "source": [
    "## Pythonを用いたシミュレーション\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa11679",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "---\n",
    "[単回帰分析とは，Albert](https://www.albert2005.co.jp/knowledge/statistics_analysis/multivariate_analysis/single_regression)\n",
    "\n",
    "[27-1.単回帰分析，統計WEB](https://bellcurve.jp/statistics/course/9700.html)\n",
    "\n",
    "[単回帰分析，日経リサーチ](https://www.nikkei-r.co.jp/glossary/id=1644)\n",
    "\n",
    "[高校数学でわかる単回帰分析，おいしい数学](https://hiraocafe.com/note/simple-linear-regression.html)\n",
    "\n",
    "[単回帰分析と重回帰分析，Chainerチュートリアル](https://tutorials.chainer.org/ja/07_Regression_Analysis.html#)\n",
    "\n",
    "[27-4.決定係数と重相関係数，統計WEB](https://bellcurve.jp/statistics/course/9706.html)\n",
    "\n",
    "[決定係数，Wikipedia](https://ja.wikipedia.org/wiki/%E6%B1%BA%E5%AE%9A%E4%BF%82%E6%95%B0)\n",
    "\n",
    "[［評価関数］決定係数（Coefficient of Determination）R2とは？，itmedia](https://atmarkit.itmedia.co.jp/ait/articles/2108/25/news033.html)\n",
    "\n",
    "[決定係数（寄与率）とは？高い場合と低い場合の解釈と相関との関係をわかりやすく，いちばんやさしい、医療統計](https://best-biostatistics.com/correlation_regression/r-square.html)\n",
    "\n",
    "[決定係数の定義と相関係数との関係，高校数学の美しい物語](https://manabitimes.jp/math/1016)\n",
    "\n",
    "[18-5.標準偏差と標準誤差，統計WEB](https://bellcurve.jp/statistics/course/8616.html)\n",
    "\n",
    "[標準誤差，Wikipedia](https://ja.wikipedia.org/wiki/%E6%A8%99%E6%BA%96%E8%AA%A4%E5%B7%AE)\n",
    "\n",
    "[標準偏差と標準誤差の違いをわかりやすく！計算式やエラーバーでの使い分けは？，いちばんやさしい、医療統計](https://best-biostatistics.com/summary/sd-se-chigai.html)\n",
    "\n",
    "[標準誤差，日経リサーチ](https://www.nikkei-r.co.jp/glossary/id=1655)\n",
    "\n",
    "[Q2 同じ実験を繰り返して得られた平均値の誤差を出すときに，標準偏差と標準誤差ではどちらを用いるのでしょうか？，実験医学online](https://www.yodosha.co.jp/jikkenigaku/statistics/q2.html)\n",
    "\n",
    "[標準偏差と標準誤差：どちらを使うべきか？](http://www.acs.dis.titech.ac.jp/suzuki/sdandse.pdf)\n",
    "\n",
    "[標準誤差とは何なのか。95％信頼区間から分かる推定精度のおはなし【視聴率を調べる手法】，アタリマエ！](https://atarimae.biz/archives/9881)\n",
    "\n",
    "[統計学の基礎　回帰式の統計モデル](http://lbm.ab.a.u-tokyo.ac.jp/~omori/kokusai/kokusai08_1218.html)\n",
    "\n",
    "[「標本平均の標準誤差」と「回帰分析の推定値の標準誤差」と「回帰係数の推定値の標準誤差」,こんてんつこうかい](https://contents-open.hatenablog.com/entry/2021/07/11/163530)\n",
    "\n",
    "[回帰係数の期待値と分散、標準誤差の計算，Pythonic HighSchool](https://ictsr4.com/py/r0160.html)\n",
    "\n",
    "[回帰分析，ようこそ、化学標準物質の不確かさへのいざない](https://staff.aist.go.jp/t.ihara/reg.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285f086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
